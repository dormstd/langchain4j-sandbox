quarkus.log.level=INFO
quarkus.http.read-timeout=120s
quarkus.langchain4j.ollama.timeout=1m

langchain4j-ollama-dev-service.ollama.host=localhost
langchain4j-ollama-dev-service.ollama.port=1234
langchain4j-ollama-dev-service.ollama.endpoint=http://${langchain4j-ollama-dev-service.ollama.host}:${langchain4j-ollama-dev-service.ollama.port}
quarkus.langchain4j.ollama.chat-model.model-id=mistral
quarkus.langchain4j.ollama.chat-model.temperature=0

%test.quarkus.langchain4j.openai.api-key=demo
# Only gpt-4o-mini is supported with the demo api-key. Using gpt-4o-mini for smoke tests is ok.
%test.quarkus.langchain4j.openai.chat-model.model-name=gpt-4o-mini